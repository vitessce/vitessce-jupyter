from pathlib import Path, PosixPath
from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider
import yaml

S3 = S3RemoteProvider()

BUCKET_VERSION = "0.0.32"
BUCKET_NAME = "vitessce-data"
BUCKET = PosixPath(BUCKET_NAME) / BUCKET_VERSION / "main"

include: "./common.smk"

# All subworkflows listed here will be
# executed as part of the 'all' rule
# in this snakefile.
subworkflow codeluppi_2018_nature_methods:
    workdir:
        "codeluppi_2018_nature_methods"
        
subworkflow combat_2022_cell:
    workdir:
        "combat_2022_cell"

subworkflow habib_2017_nature_methods:
    workdir:
        "habib_2017_nature_methods"

subworkflow human_lymph_node_10x_visium:
    workdir:
        "human_lymph_node_10x_visium"


# Only access workflow._subworkflows after all
# subworkflows have been defined above.
SUBWORKFLOW_KEYS = workflow._subworkflows.keys()

def get_subworkflow_outputs(subworkflow_key):
    with open(Path(subworkflow_key) / "config.yml") as f:
        subworkflow_config = yaml.load(f, Loader=yaml.SafeLoader)
        return subworkflow_config['output']

rule all:
    input:
        in_files=[
            [
                globals()[subworkflow_key](str(PROCESSED_DIR / subworkflow_output))
                for subworkflow_output
                in get_subworkflow_outputs(subworkflow_key)
            ]
            for subworkflow_key
            in SUBWORKFLOW_KEYS
        ]
    params:
        should_upload=config.get("upload"),
        # This should be in output: https://github.com/snakemake/snakemake/issues/870
        out_files=[
            [
                S3.remote(str(BUCKET / subworkflow_key / subworkflow_output))
                for subworkflow_output
                in get_subworkflow_outputs(subworkflow_key)
            ]
            for subworkflow_key
            in SUBWORKFLOW_KEYS
        ]
    run:
        if str2bool(params.should_upload):
            print("Uploading")
            for in_file, out_file in zip(input.in_files, flatten(params.out_files)):
                shell(f"aws s3 cp --recursive {in_file} s3://{out_file}")
        else:
            print("Not uploading. To upload, use snakemake --config upload=true")
            for in_file, out_file in zip(input.in_files, flatten(params.out_files)):
                shell(f"echo \"{in_file} s3://{out_file}\"")
